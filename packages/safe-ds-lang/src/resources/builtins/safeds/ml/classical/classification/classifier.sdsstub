package safeds.ml.classical.classification

from safeds.data.labeled.containers import TabularDataset
from safeds.data.tabular.containers import Table

/**
 * Abstract base class for all classifiers.
 */
class Classifier {
    /**
     * Whether the classifier is fitted.
     */
    @PythonName("is_fitted") attr isFitted: Boolean

    /**
     * Create a copy of this classifier and fit it with the given training data.
     *
     * This classifier is not modified.
     *
     * @param trainingSet The training data containing the feature and target vectors.
     *
     * @result fittedClassifier The fitted classifier.
     */
    @Pure
    fun fit(
        @PythonName("training_set") trainingSet: TabularDataset
    ) -> fittedClassifier: Classifier

    /**
     * Predict a target vector using a dataset containing feature vectors. The model has to be trained first.
     *
     * @param dataset The dataset containing the feature vectors.
     *
     * @result prediction A dataset containing the given feature vectors and the predicted target vector.
     */
    @Pure
    fun predict(
        dataset: Table
    ) -> prediction: TabularDataset

    /**
     * Compute the accuracy of the classifier on the given data.
     *
     * @param validationOrTestSet The validation or test set.
     *
     * @result accuracy The calculated accuracy score, i.e. the percentage of equal data.
     */
    @Pure
    fun accuracy(
        @PythonName("validation_or_test_set") validationOrTestSet: TabularDataset
    ) -> accuracy: Float

    /**
     * Compute the classifier's precision on the given data.
     *
     * @param validationOrTestSet The validation or test set.
     * @param positiveClass The class to be considered positive. All other classes are considered negative.
     *
     * @result precision The calculated precision score, i.e. the ratio of correctly predicted positives to all predicted positives.
     * Return 1 if no positive predictions are made.
     */
    @Pure
    fun precision(
        @PythonName("validation_or_test_set") validationOrTestSet: TabularDataset,
        @PythonName("positive_class") positiveClass: Any
    ) -> precision: Float

    /**
     * Compute the classifier's recall on the given data.
     *
     * @param validationOrTestSet The validation or test set.
     * @param positiveClass The class to be considered positive. All other classes are considered negative.
     *
     * @result recall The calculated recall score, i.e. the ratio of correctly predicted positives to all expected positives.
     * Return 1 if there are no positive expectations.
     */
    @Pure
    fun recall(
        @PythonName("validation_or_test_set") validationOrTestSet: TabularDataset,
        @PythonName("positive_class") positiveClass: Any
    ) -> recall: Float

    /**
     * Compute the classifier's $F_1$-score on the given data.
     *
     * @param validationOrTestSet The validation or test set.
     * @param positiveClass The class to be considered positive. All other classes are considered negative.
     *
     * @result f1Score The calculated $F_1$-score, i.e. the harmonic mean between precision and recall.
     * Return 1 if there are no positive expectations and predictions.
     */
    @Pure
    @PythonName("f1_score")
    fun f1Score(
        @PythonName("validation_or_test_set") validationOrTestSet: TabularDataset,
        @PythonName("positive_class") positiveClass: Any
    ) -> f1Score: Float
}
