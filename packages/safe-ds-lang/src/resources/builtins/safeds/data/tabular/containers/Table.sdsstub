package safeds.data.tabular.containers

from safeds.data.labeled.containers import TabularDataset
from safeds.data.tabular.plotting import TablePlotter
from safeds.data.tabular.transformation import InvertibleTableTransformer
from safeds.data.tabular.transformation import TableTransformer
from safeds.data.tabular.typing import ColumnType
from safeds.data.tabular.typing import Schema

/**
 * A two-dimensional collection of data. It can either be seen as a list of rows or as a list of columns.
 *
 * To create a `Table` call the constructor or use one of the following static methods:
 *
 * - {@link Table.fromCsvFile}: Create a table from a CSV file.
 * - {@link Table.fromJsonFile}: Create a table from a JSON file.
 * - {@link Table.fromParquetFile}: Create a table from a Parquet file.
 * - {@link Table.fromColumns}: Create a table from a list of columns.
 * - {@link Table.fromMap}: Create a table from a map.
 *
 * @param data The data of the table. If null, an empty table is created.
 *
 * @example
 * pipeline example {
 *     out Table({"a": [1, 2, 3], "b": [4, 5, 6]});
 * }
 */
@Category(DataScienceCategory.BasicElement)
class Table(
    data: Map<String, List<Any?>>
) {
    /**
     * The number of columns.
     *
     * **Note:** This operation must compute the schema of the table, which can be expensive.
     */
    @PythonName("column_count") attr columnCount: Int
    /**
     * The names of the columns in the table.
     *
     * **Note:** This operation must compute the schema of the table, which can be expensive.
     */
    @PythonName("column_names") attr columnNames: List<String>
    /**
     * The number of rows.
     *
     * **Note:** This operation must fully load the data into memory, which can be expensive.
     */
    @PythonName("row_count") attr rowCount: Int
    /**
     * The plotter for the table.
     *
     * Call methods of the plotter to create various plots for the table.
     */
    attr plot: TablePlotter
    /**
     * The schema of the table, which is a mapping from column names to their types.
     *
     * **Note:** This operation must compute the schema of the table, which can be expensive.
     */
    attr schema: Schema

    /**
     * Create a table from columns.
     *
     * @param columns The columns.
     *
     * @result table The created table.
     *
     * @example
     * pipeline example {
     *     val a = Column("a", [1, 2, 3]);
     *     val b = Column("b", [4, 5, 6]);
     *     out Table.fromColumns([a, b]);
     * }
     */
    @Pure
    @PythonName("from_columns")
    @Category(DataScienceCategory.UtilitiesQConversion)
    static fun fromColumns(
        columns: union<Column, List<Column>>
    ) -> table: Table

    /**
     * Create a table from a CSV file.
     *
     * @param path The path to the CSV file. If the file extension is omitted, it is assumed to be ".csv".
     * @param separator The separator between the values in the CSV file.
     *
     * @result table The created table.
     *
     * @example
     * pipeline example {
     *     out Table.fromCsvFile("./src/resources/fromCsvFile.csv");
     * }
     */
    @Impure([ImpurityReason.FileReadFromParameterizedPath("path")])
    @PythonName("from_csv_file")
    @Category(DataScienceCategory.DataImport)
    static fun fromCsvFile(
        path: String,
        separator: String = ","
    ) -> table: Table

    /**
     * Create a table from a map that maps column names to column values.
     *
     * @param data The data.
     *
     * @result table The generated table.
     *
     * @example
     * pipeline example {
     *     val data = {"a": [1, 2, 3], "b": [4, 5, 6]};
     *     out Table.fromMap(data);
     * }
     */
    @Pure
    @PythonName("from_dict")
    @Category(DataScienceCategory.DataImport)
    static fun fromMap(
        data: Map<String, List<Any>>
    ) -> table: Table

    /**
     * Create a table from a JSON file.
     *
     * @param path The path to the JSON file. If the file extension is omitted, it is assumed to be ".json".
     *
     * @result table The created table.
     *
     * @example
     * pipeline example {
     *     out Table.fromJsonFile("./src/resources/fromJsonFile.json");
     * }
     */
    @Impure([ImpurityReason.FileReadFromParameterizedPath("path")])
    @PythonName("from_json_file")
    @Category(DataScienceCategory.DataImport)
    static fun fromJsonFile(
        path: String
    ) -> table: Table

    /**
     * Create a table from a Parquet file.
     *
     * @param path The path to the Parquet file. If the file extension is omitted, it is assumed to be ".parquet".
     *
     * @result table The created table.
     *
     * @example
     * pipeline example {
     *     out Table.fromParquetFile("./src/resources/fromParquetFile.parquet");
     * }
     */
    @Impure([ImpurityReason.FileReadFromParameterizedPath("path")])
    @PythonName("from_parquet_file")
    @Category(DataScienceCategory.DataImport)
    static fun fromParquetFile(
        path: String
    ) -> table: Table

    /**
     * Add columns to the table and return the result as a new table.
     *
     * **Note:** The original table is not modified.
     *
     * @param columns The columns to add.
     *
     * @result newTable The table with the additional columns.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3]});
     *     val newColumn = Column("b", [4, 5, 6]);
     *     out table.addColumns(newColumn);
     * }
     */
    @Pure
    @PythonName("add_columns")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun addColumns(
        columns: union<Column, List<Column>, Table>
    ) -> newTable: Table

    /**
     * Add a computed column to the table and return the result as a new table.
     *
     * **Note:** The original table is not modified.
     *
     * @param name The name of the new column.
     * @param computer The function that computes the values of the new column.
     *
     * @result newTable The table with the computed column.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     out table.addComputedColumn("c", (row) -> row["a"] + row["b"]);
     * }
     */
    @Pure
    @PythonName("add_computed_column")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun addComputedColumn(
        name: String,
        computer: (row: Row) -> cell: Cell
    ) -> newTable: Table

    /**
     * Add an index column to the table and return the result as a new table.
     *
     * **Note:** The original table is not modified.
     *
     * @param name The name of the new column.
     * @param firstIndex The index to assign to the first row. Must be greater or equal to 0.
     *
     * @result newTable The table with the index column.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     out table.addIndexColumn("id");
     *     out table.addIndexColumn("id", firstIndex = 10);
     * }
     */
    @Pure
    @PythonName("add_index_column")
    fun addIndexColumn(
        name: String,
        @PythonName("first_index") firstIndex: Int = 0
    ) -> newTable: Table

    /**
     * Get a column from the table.
     *
     * @param name The name of the column.
     *
     * @result column The column.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     out table.getColumn("a");
     * }
     */
    @Pure
    @PythonName("get_column")
    @Category(DataScienceCategory.UtilitiesQTable)
    fun getColumn(
        name: String
    ) -> column: Column<Any>

    /**
     * Get the type of a column.
     *
     * @param name The name of the column.
     *
     * @result type The type of the column.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     out table.getColumnType("a");
     * }
     */
    @Pure
    @PythonName("get_column_type")
    @Category(DataScienceCategory.UtilitiesQTable)
    fun getColumnType(
        name: String
    ) -> type: ColumnType

    /**
     * Check if the table has a column with a specific name.
     *
     * @param name The name of the column.
     *
     * @result hasColumn Whether the table has a column with the specified name.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     out table.hasColumn("a");
     *     out table.hasColumn("c");
     * }
     */
    @Pure
    @PythonName("has_column")
    @Category(DataScienceCategory.UtilitiesQTable)
    fun hasColumn(
        name: String
    ) -> hasColumn: Boolean

    /**
     * Remove the specified columns from the table and return the result as a new table.
     *
     * **Note:** The original table is not modified.
     *
     * @param selector The columns to remove.
     * @param ignoreUnknownNames If set to true, columns that are not present in the table will be ignored.
     * If set to false, an error will be raised if any of the specified columns do not exist.
     *
     * @result newTable The table with the columns removed.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     out table.removeColumns("a");
     *     out table.removeColumns(["c"], ignoreUnknownNames = true);
     * }
     */
    @Pure
    @PythonName("remove_columns")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun removeColumns(
        selector: union<List<String>, String>,
        @PythonName("ignore_unknown_names") ignoreUnknownNames: Boolean = false
    ) -> newTable: Table

    /**
     * Remove columns with too many missing values and return the result as a new table.
     *
     * How many missing values are allowed is determined by the `missing_value_ratio_threshold` parameter. A column is
     * removed if its missing value ratio is greater than the threshold. By default, a column is removed if it contains
     * any missing values.
     *
     * **Notes:**
     *
     * - The original table is not modified.
     * - This operation must fully load the data into memory, which can be expensive.
     *
     * @param missingValueRatioThreshold The maximum missing value ratio a column can have to be kept (inclusive). Must be between 0 and 1.
     *
     * @result newTable The table without columns that contain too many missing values.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, null]});
     *     out table.removeColumnsWithMissingValues();
     * }
     */
    @Pure
    @PythonName("remove_columns_with_missing_values")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun removeColumnsWithMissingValues() -> newTable: Table

    /**
     * Remove non-numeric columns and return the result as a new table.
     *
     * **Note:** The original table is not modified.
     *
     * @result newTable The table without non-numeric columns.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": ["4", "5", "6"]});
     *     out table.removeNonNumericColumns();
     * }
     */
    @Pure
    @PythonName("remove_non_numeric_columns")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun removeNonNumericColumns() -> newTable: Table

    /**
     * Rename a column and return the result as a new table.
     *
     * **Note:** The original table is not modified.
     *
     * @param oldName The name of the column to rename.
     * @param newName The new name of the column.
     *
     * @result newTable The table with the column renamed.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     out table.renameColumn("a", "c");
     * }
     */
    @Pure
    @PythonName("rename_column")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun renameColumn(
        @PythonName("old_name") oldName: String,
        @PythonName("new_name") newName: String
    ) -> newTable: Table

    /**
     * Replace a column with zero or more columns and return the result as a new table.
     *
     * **Note:** The original table is not modified.
     *
     * @param oldName The name of the column to replace.
     * @param newColumns The new columns.
     *
     * @result newTable The table with the column replaced.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     val column1 = Column("c", [7, 8, 9]);
     *     val column2 = Column("d", [10, 11, 12]);
     *     out table.replaceColumn("a", []);
     *     out table.replaceColumn("a", column1);
     *     out table.replaceColumn("a", [column1, column2]);
     * }
     */
    @Pure
    @PythonName("replace_column")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun replaceColumn(
        @PythonName("old_name") oldName: String,
        @PythonName("new_columns") newColumns: union<Column<Any>, List<Column<Any>>, Table>
    ) -> newTable: Table

    /**
     * Select a subset of the columns and return the result as a new table.
     *
     * **Note:** The original table is not modified.
     *
     * @param selector The columns to keep.
     *
     * @result newTable The table with only a subset of the columns.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     out table.selectColumns("a");
     * }
     */
    @Pure
    @PythonName("select_columns")
    fun selectColumns(
        selector: union<List<String>, String>
    ) -> newTable: Table

    /**
     * Transform columns with a custom function and return the result as a new table.
     *
     * **Note:** The original table is not modified.
     *
     * @param selector The names of the columns to transform.
     * @param transformer The function that computes the new values. It may take either a single cell or a cell and the entire row as
     * arguments (see examples).
     *
     * @result newTable The table with the transformed column.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     out table.transformColumns("a", (cell, row) -> cell + 1);
     *     out table.transformColumns(["a", "b"], (cell, row) -> cell + 1);
     *     out table.transformColumns("a", (cell, row) -> cell + row["b"]);
     * }
     */
    @Pure
    @PythonName("transform_columns")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun transformColumns(
        selector: union<List<String>, String>,
        transformer: (cell: Cell, row: Row) -> result: Cell
    ) -> newTable: Table

    /**
     * Count how many rows in the table satisfy the predicate.
     *
     * The predicate can return one of three results:
     *
     * * true, if the row satisfies the predicate.
     * * false, if the row does not satisfy the predicate.
     * * null, if the truthiness of the predicate is unknown, e.g. due to missing values.
     *
     * By default, cases where the truthiness of the predicate is unknown are ignored and this method returns how
     * often the predicate returns true.
     *
     * You can instead enable Kleene logic by setting `ignoreUnknown = false`. In this case, this method returns null if
     * the predicate returns null at least once. Otherwise, it still returns how often the predicate returns true.
     *
     * @param predicate The predicate to apply to each row.
     * @param ignoreUnknown Whether to ignore cases where the truthiness of the predicate is unknown.
     *
     * @result count The number of rows in the table that satisfy the predicate.
     *
     * @example
     * pipeline example {
     *     val table = Table({"col1": [1, 2, 3], "col2": [1, 3, null]});
     *     out table.countRowsIf((row) -> row["col1"] < row["col2"]);
     *     out table.countRowsIf((row) -> row["col1"] < row["col2"], ignoreUnknown = false);
     * }
     */
    @Pure
    @PythonName("count_rows_if")
    fun countRowsIf(
        predicate: (row: Row) -> satisfiesPredicate: Cell<Boolean?>,
        @PythonName("ignore_unknown") ignoreUnknown: Boolean = true
    ) -> count: Int?

    /**
     * Keep only rows that satisfy a condition and return the result as a new table.
     *
     * **Note:** The original table is not modified.
     *
     * @param predicate The function that determines which rows to keep.
     *
     * @result newTable The table containing only the specified rows.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     out table.filterRows((row) -> row["a"] == 2);
     * }
     */
    @Pure
    @PythonName("filter_rows")
    fun filterRows(
        predicate: (row: Row) -> satisfiedPredicate: Cell<Boolean?>
    ) -> newTable: Table

    /**
     * Keep only rows that satisfy a condition on a specific column and return the result as a new table.
     *
     * **Note:** The original table is not modified.
     *
     * @param name The name of the column.
     * @param predicate The function that determines which rows to keep.
     *
     * @result newTable The table containing only the specified rows.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     out table.filterRowsByColumn("a", (cell) -> cell == 2);
     * }
     */
    @Pure
    @PythonName("filter_rows_by_column")
    fun filterRowsByColumn(
        name: String,
        predicate: (cell: Cell) -> satisfiesPredicate: Cell<Boolean?>
    ) -> newTable: Table

    /**
     * Remove duplicate rows and return the result as a new table.
     *
     * **Note:** The original table is not modified.
     *
     * @result newTable The table without duplicate rows.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 2], "b": [4, 5, 5]});
     *     out table.removeDuplicateRows();
     * }
     */
    @Pure
    @PythonName("remove_duplicate_rows")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun removeDuplicateRows() -> newTable: Table

    /**
     * Remove rows that satisfy a condition and return the result as a new table.
     *
     * **Note:** The original table is not modified.
     *
     * @param predicate The function that determines which rows to remove.
     *
     * @result newTable The table without the specified rows.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     out table.removeRows((row) -> row["a"] == 2);
     * }
     */
    @Pure
    @PythonName("remove_rows")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun removeRows(
        predicate: (row: Row) -> satisfiesPredicate: Cell<Boolean?>
    ) -> newTable: Table

    /**
     * Remove rows that satisfy a condition on a specific column and return the result as a new table.
     *
     * **Note:** The original table is not modified.
     *
     * @param name The name of the column.
     * @param predicate The function that determines which rows to remove.
     *
     * @result newTable The table without the specified rows.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     out table.removeRowsByColumn("a", (cell) -> cell == 2);
     * }
     */
    @Pure
    @PythonName("remove_rows_by_column")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun removeRowsByColumn(
        name: String,
        predicate: (cell: Cell<Any>) -> satisfiesPredicate: Cell<Boolean?>
    ) -> newTable: Table

    /**
     * Remove rows that contain missing values in the specified columns and return the result as a new table.
     *
     * The resulting table no longer has missing values in the specified columns. Be aware that this method can discard
     * a lot of data. Consider first removing columns with many missing values, or using one of the imputation methods
     * (see "Related" section).
     *
     * **Note:** The original table is not modified.
     *
     * @param selector The columns to check. If null, all columns are checked.
     *
     * @result newTable The table without rows that contain missing values in the specified columns.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, null, 3], "b": [4, 5, null]});
     *     out table.removeRowsWithMissingValues();
     *     out table.removeRowsWithMissingValues(selector = ["b"]);
     * }
     */
    @Pure
    @PythonName("remove_rows_with_missing_values")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun removeRowsWithMissingValues(
        selector: union<List<String>, String, Nothing?> = null
    ) -> newTable: Table

    /**
     * Remove rows that contain outliers in the specified columns and return the result as a new table.
     *
     * Whether a value is an outlier in a column is determined by its z-score. The z-score the distance of the value
     * from the mean of the column divided by the standard deviation of the column. If the z-score is greater than the
     * given threshold, the value is considered an outlier. Missing values are ignored during the calculation of the
     * z-score.
     *
     * The z-score is only defined for numeric columns. Non-numeric columns are ignored, even if they are specified in
     * `column_names`.
     *
     * **Notes:**
     *
     * - The original table is not modified.
     * - This operation must fully load the data into memory, which can be expensive.
     *
     * @param selector The columns to check. If null, all columns are checked.
     * @param zScoreThreshold The z-score threshold for detecting outliers. Must be greater than or equal to 0.
     *
     * @result newTable The table without rows that contain outliers in the specified columns.
     *
     * @example
     * pipeline example {
     *     val table = Table(
     *         {
     *             "a": [1, 2, 3, 4, 5, 6, 1000, null],
     *             "b": [1, 2, 3, 4, 5, 6,    7,    8],
     *         }
     *     );
     *     out table.removeRowsWithOutliers(zScoreThreshold = 2);
     * }
     */
    @Pure
    @PythonName("remove_rows_with_outliers")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun removeRowsWithOutliers(
        selector: union<List<String>, String, Nothing?> = null,
        @PythonName("z_score_threshold") zScoreThreshold: Float = 3
    ) -> newTable: Table

    /**
     * Shuffle the rows and return the result as a new table.
     *
     * **Notes:**
     *
     * - The original table is not modified.
     * - This operation must fully load the data into memory, which can be expensive.
     *
     * @param randomSeed The seed for the pseudorandom number generator.
     *
     * @result newTable The table with the rows shuffled.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     out table.shuffleRows();
     * }
     */
    @Pure
    @PythonName("shuffle_rows")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun shuffleRows(
        @PythonName("random_seed") randomSeed: Int = 0
    ) -> newTable: Table

    /**
     * Slice the rows and return the result as a new table.
     *
     * **Note:** The original table is not modified.
     *
     * @param start The start index of the slice. Nonnegative indices are counted from the beginning (starting at 0), negative
     * indices from the end (starting at -1).
     * @param length The length of the slice. If null, the slice contains all rows starting from `start`. Must greater than or
     * equal to 0.
     *
     * @result newTable The table with the slice of rows.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     out table.sliceRows(start = 1);
     *     out table.sliceRows(start = 1, length = 1);
     * }
     */
    @Pure
    @PythonName("slice_rows")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun sliceRows(
        start: Int = 0,
        length: Int? = null
    ) -> newTable: Table

    /**
     * Sort the rows by a custom function and return the result as a new table.
     *
     * **Note:** The original table is not modified.
     *
     * @param keySelector The function that selects the key to sort by.
     * @param descending Whether to sort in descending order.
     *
     * @result newTable The table with the rows sorted.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [2, 1, 3], "b": [1, 1, 2]});
     *     out table.sortRows((row) -> row["a"] - row["b"]);
     * }
     */
    @Pure
    @PythonName("sort_rows")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun sortRows(
        @PythonName("key_selector") keySelector: (row: Row) -> key: Cell,
        descending: Boolean = false
    ) -> newTable: Table

    /**
     * Sort the rows by a specific column and return the result as a new table.
     *
     * **Note:** The original table is not modified.
     *
     * @param name The name of the column to sort by.
     * @param descending Whether to sort in descending order.
     *
     * @result newTable The table with the rows sorted by the specified column.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [2, 1, 3], "b": [1, 1, 2]});
     *     out table.sortRowsByColumn("a");
     * }
     */
    @Pure
    @PythonName("sort_rows_by_column")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun sortRowsByColumn(
        name: String,
        descending: Boolean = false
    ) -> newTable: Table

    /**
     * Create two tables by splitting the rows of the current table.
     *
     * The first table contains a percentage of the rows specified by `percentage_in_first`, and the second table
     * contains the remaining rows. By default, the rows are shuffled before splitting. You can disable this by setting
     * `shuffle` to false.
     *
     * **Notes:**
     *
     * - The original table is not modified.
     * - This operation must fully load the data into memory, which can be expensive.
     *
     * @param percentageInFirst The percentage of rows to include in the first table. Must be between 0 and 1.
     * @param shuffle Whether to shuffle the rows before splitting.
     * @param randomSeed The seed for the pseudorandom number generator used for shuffling.
     *
     * @result firstTable The first table.
     * @result secondTable The second table.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3, 4, 5], "b": [6, 7, 8, 9, 10]});
     *     out table.splitRows(0.6);
     * }
     */
    @Pure
    @PythonName("split_rows")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun splitRows(
        @PythonName("percentage_in_first") percentageInFirst: Float,
        shuffle: Boolean = true,
        @PythonName("random_seed") randomSeed: Int = 0
    ) -> (firstTable: Table, secondTable: Table)

    /**
     * Add the columns of other tables and return the result as a new table.
     *
     * **Note:** The original tables are not modified.
     *
     * @param others The tables to add as columns.
     *
     * @result newTable The table with the columns added.
     *
     * @example
     * pipeline example {
     *     val table1 = Table({"a": [1, 2, 3]});
     *     val table2 = Table({"b": [4, 5, 6]});
     *     out table1.addTablesAsColumns(table2);
     * }
     */
    @Pure
    @PythonName("add_tables_as_columns")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun addTablesAsColumns(
        others: union<List<Table>, Table>
    ) -> newTable: Table

    /**
     * Add the rows of other tables and return the result as a new table.
     *
     * **Note:** The original tables are not modified.
     *
     * @param others The tables to add as rows.
     *
     * @result newTable The table with the rows added.
     *
     * @example
     * pipeline example {
     *     val table1 = Table({"a": [1, 2, 3]});
     *     val table2 = Table({"a": [4, 5, 6]});
     *     out table1.addTablesAsRows(table2);
     * }
     */
    @Pure
    @PythonName("add_tables_as_rows")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun addTablesAsRows(
        others: union<List<Table>, Table>
    ) -> newTable: Table

    /**
     * Inverse-transform the table by a **fitted, invertible** transformer and return the result as a new table.
     *
     * **Notes:**
     *
     * - The original table is not modified.
     * - Depending on the transformer, this operation might fully load the data into memory, which can be expensive.
     *
     * @param fittedTransformer The fitted, invertible transformer to apply.
     *
     * @result newTable The inverse-transformed table.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3]});
     *     val transformer, val transformedTable = RangeScaler(min = 0, max = 1).fitAndTransform(table);
     *     out transformedTable.inverseTransformTable(transformer);
     * }
     */
    @Pure
    @PythonName("inverse_transform_table")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun inverseTransformTable(
        @PythonName("fitted_transformer") fittedTransformer: InvertibleTableTransformer
    ) -> newTable: Table

    /**
     * Join the current table (left table) with another table (right table) and return the result as a new table.
     *
     * Rows are matched if the values in the specified columns are equal. The parameter `left_names` controls which
     * columns are used for the left table, and `right_names` does the same for the right table.
     *
     * There are various types of joins, specified by the `mode` parameter:
     *
     * - `"inner"`:
     *     Keep only rows that have matching values in both tables.
     * - `"left"`:
     *     Keep all rows from the left table and the matching rows from the right table. Cells with no match are
     *     marked as missing values.
     * - `"right"`:
     *     Keep all rows from the right table and the matching rows from the left table. Cells with no match are
     *     marked as missing values.
     * - `"full"`:
     *     Keep all rows from both tables. Cells with no match are marked as missing values.
     *
     * **Note:** The original tables are not modified.
     *
     * @param rightTable The table to join with the left table.
     * @param leftNames Names of columns to join on in the left table.
     * @param rightNames Names of columns to join on in the right table.
     * @param mode Specify which type of join you want to use.
     *
     * @result newTable The table with the joined table.
     *
     * @example
     * pipeline example {
     *     val table1 = Table({"a": [1, 2], "b": [true, false]});
     *     val table2 = Table({"c": [1, 3], "d": ["a", "b"]});
     *     out table1.join(table2, "a", "c", mode="inner");
     *     out table1.join(table2, "a", "c", mode="left");
     *     out table1.join(table2, "a", "c", mode="right");
     *     out table1.join(table2, "a", "c", mode="full");
     * }
     */
    @Pure
    @Category(DataScienceCategory.DataProcessingQTable)
    fun join(
        @PythonName("right_table") rightTable: Table,
        @PythonName("left_names") leftNames: union<List<String>, String>,
        @PythonName("right_names") rightNames: union<List<String>, String>,
        mode: literal<"inner", "left", "right", "full"> = "inner"
    ) -> newTable: Table

    /**
     * Transform the table with a **fitted** transformer and return the result as a new table.
     *
     * **Notes:**
     *
     * - The original table is not modified.
     * - Depending on the transformer, this operation might fully load the data into memory, which can be expensive.
     *
     * @param fittedTransformer The fitted transformer to apply.
     *
     * @result newTable The transformed table.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3]});
     *     val transformer = RangeScaler(min = 0, max = 1).fit(table);
     *     out table.transformTable(transformer);
     * }
     */
    @Pure
    @PythonName("transform_table")
    @Category(DataScienceCategory.DataProcessingQTable)
    fun transformTable(
        @PythonName("fitted_transformer") fittedTransformer: TableTransformer
    ) -> newTable: Table

    /**
     * Return a table with important statistics about this table.
     *
     * !!! warning "API Stability"
     *
     *     Do not rely on the exact output of this method. In future versions, we may change the displayed statistics
     *     without prior notice.
     *
     * @result statistics The table with statistics.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 3]});
     *     out table.summarizeStatistics();
     * }
     */
    @Pure
    @PythonName("summarize_statistics")
    @Category(DataScienceCategory.DataExplorationQMetric)
    fun summarizeStatistics() -> statistics: Table

    /**
     * Return the data of the table as a list of columns.
     *
     * @result columns The columns of the table.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     out table.toColumns();
     * }
     */
    @Pure
    @PythonName("to_columns")
    @Category(DataScienceCategory.UtilitiesQConversion)
    fun toColumns() -> columns: List<Column>

    /**
     * Write the table to a CSV file.
     *
     * If the file and/or the parent directories do not exist, they will be created. If the file exists already, it
     * will be overwritten.
     *
     * @param path The path to the CSV file. If the file extension is omitted, it is assumed to be ".csv".
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     table.toCsvFile("./src/resources/toCsvFile.csv");
     * }
     */
    @Impure([ImpurityReason.FileWriteToParameterizedPath("path")])
    @PythonName("to_csv_file")
    @Category(DataScienceCategory.DataExport)
    fun toCsvFile(
        path: String
    )

    /**
     * Return a map from column names to column values.
     *
     * **Note:** This operation must fully load the data into memory, which can be expensive.
     *
     * @result map The map representation of the table.
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     out table.toMap();
     * }
     */
    @Pure
    @PythonName("to_dict")
    @Category(DataScienceCategory.UtilitiesQConversion)
    fun toMap() -> map: Map<String, List<Any>>

    /**
     * Write the table to a JSON file.
     *
     * If the file and/or the parent directories do not exist, they will be created. If the file exists already, it
     * will be overwritten.
     *
     * **Note:** This operation must fully load the data into memory, which can be expensive.
     *
     * @param path The path to the JSON file. If the file extension is omitted, it is assumed to be ".json".
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     table.toJsonFile("./src/resources/toJsonFile.json");
     * }
     */
    @Impure([ImpurityReason.FileWriteToParameterizedPath("path")])
    @PythonName("to_json_file")
    @Category(DataScienceCategory.DataExport)
    fun toJsonFile(
        path: String
    )

    /**
     * Write the table to a Parquet file.
     *
     * If the file and/or the parent directories do not exist, they will be created. If the file exists already, it
     * will be overwritten.
     *
     * @param path The path to the Parquet file. If the file extension is omitted, it is assumed to be ".parquet".
     *
     * @example
     * pipeline example {
     *     val table = Table({"a": [1, 2, 3], "b": [4, 5, 6]});
     *     table.toParquetFile("./src/resources/toParquetFile.parquet");
     * }
     */
    @Impure([ImpurityReason.FileWriteToParameterizedPath("path")])
    @PythonName("to_parquet_file")
    @Category(DataScienceCategory.DataExport)
    fun toParquetFile(
        path: String
    )

    /**
     * Return a new `TabularDataset` with columns marked as a target, feature, or extra.
     *
     * - The target column is the column that a model should predict.
     * - Feature columns are columns that a model should use to make predictions.
     * - Extra columns are columns that are neither feature nor target. They are ignored by models and can be used to
     *   provide additional context. An ID or name column is a common example.
     *
     * Feature columns are implicitly defined as all columns except the target and extra columns. If no extra columns
     * are specified, all columns except the target column are used as features.
     *
     * @param targetName The name of the target column.
     * @param extraNames Names of the columns that are neither features nor target. If null, no extra columns are used, i.e. all but
     * the target column are used as features.
     *
     * @example
     * pipeline example {
     *     val table = Table(
     *         {
     *             "extra": [1, 2, 3],
     *             "feature": [4, 5, 6],
     *             "target": [7, 8, 9],
     *         },
     *     );
     *     out table.toTabularDataset("target", extraNames="extra");
     * }
     */
    @Pure
    @PythonName("to_tabular_dataset")
    @Category(DataScienceCategory.UtilitiesQConversion)
    fun toTabularDataset(
        @PythonName("target_name") targetName: String,
        @PythonName("extra_names") extraNames: union<List<String>, String, Nothing?> = null
    ) -> dataset: TabularDataset
}
